# ML_text_model

## Описание проекта:

Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию. В нашем распоряжении набор данных с разметкой о токсичности правок.

#### В работе используются следующие модели:

- LogisticRegression — логистическая регрессия
- DecisionTreeClassifier  — деревья решений для задач классификации
  
## Цель исследования:

- Необходимо обучить модель классифицировать комментарии на позитивные и негативные. 
- У модели значение метрики качества `F1` должно быть не меньше 0.75.

## Как запустить проект

- Открыть файл `ML_text_model` в GitHub
  

## Краткие результаты

- Проведена подготовка данных: добавили столбец `corpus` с очищенным и лемматизированным текстом из столбца `text`;
- Проведен исследовательский анализ данных целевого признака:
    - целевой признак `toxic` имеет дисбаланс классов;
    - самое популярное слово в корректных комментариях — `article` *(статья)*;
    - самое популярное слово в токсичных комментариях — `f*ck` *(нецензурное слово)*;
    - средняя длина слова в токсичных и корректных комментариях одинакова и составляет 4 буквы;
    - средняя длина корректных комментариев превышает среднюю длину токсичных комментариев.
- По итогам работы `OptunaSearchCV` и `Pipeline` мы получили лучшую модель `LogisticRegression` с гиперпараметрами: `(random_state=RANDOM_STATE, max_iter=1000, C=16.674692129512426)`, методом векторизации `TfidfVectorizer(ngram_range': (1, 1))` и значением метрики `F1` на тестовых данных `0.79`.
